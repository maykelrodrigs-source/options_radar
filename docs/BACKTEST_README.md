# ğŸ”¬ MÃ³dulo de Backtest do ProfessionalAnalyzer

Este mÃ³dulo implementa um sistema completo de backtest para validar a eficÃ¡cia do ProfessionalAnalyzer em dados histÃ³ricos.

## ğŸ“ Arquivos Criados

### `backtest.py`
- **BacktestEngine**: Engine principal para execuÃ§Ã£o de backtests
- **BacktestResult**: Estrutura de dados com resultados completos
- **BacktestSignal**: Representa cada sinal individual gerado
- Funcionalidades:
  - ExecuÃ§Ã£o de backtest em janelas mÃ³veis (rolling window)
  - ValidaÃ§Ã£o de sinais CALL/PUT/NEUTRAL
  - CÃ¡lculo de estatÃ­sticas de acurÃ¡cia
  - ExportaÃ§Ã£o para DataFrame/CSV

### `plots.py`
- **BacktestPlotter**: Classe para gerar visualizaÃ§Ãµes interativas
- GrÃ¡ficos disponÃ­veis:
  - PreÃ§o do ativo com marcadores de sinais
  - Breakdown de acurÃ¡cia por tipo e confianÃ§a
  - DistribuiÃ§Ã£o de retornos
  - ConfianÃ§a vs Resultado (scatter plot)
  - Performance temporal (rolling accuracy)

### `run_backtest.py`
- Interface Streamlit completa para execuÃ§Ã£o de backtests
- ConfiguraÃ§Ã£o de parÃ¢metros via sidebar
- VisualizaÃ§Ã£o interativa dos resultados
- ExportaÃ§Ã£o de dados e relatÃ³rios
- Insights automÃ¡ticos baseados na performance

## ğŸš€ Como Usar

### 1. Interface Streamlit (Recomendado)

```bash
streamlit run run_backtest.py
```

Ou acesse pela aba "ğŸ”¬ Backtest" no app principal:

```bash
streamlit run app.py
```

### 2. Uso ProgramÃ¡tico

```python
from datetime import datetime, timedelta
from backtest import BacktestEngine
from plots import BacktestPlotter

# Cria engine
engine = BacktestEngine(success_threshold=3.0)

# Configura perÃ­odo
end_date = datetime.now()
start_date = end_date - timedelta(days=730)  # 2 anos

# Executa backtest
result = engine.run_backtest(
    ticker="PETR4",
    start_date=start_date,
    end_date=end_date,
    evaluation_days=20,
    rolling_window=5
)

# Visualiza resultados
engine.print_summary(result)

# Gera grÃ¡ficos
plotter = BacktestPlotter()
fig = plotter.plot_price_with_signals(result)
fig.show()
```

## âš™ï¸ ParÃ¢metros de ConfiguraÃ§Ã£o

### BacktestEngine
- **ticker**: CÃ³digo do ativo (ex: PETR4)
- **start_date/end_date**: PerÃ­odo do backtest
- **evaluation_days**: Dias Ãºteis para avaliar se sinal acertou (padrÃ£o: 20)
- **rolling_window**: Intervalo entre anÃ¡lises em dias Ãºteis (padrÃ£o: 5)
- **success_threshold**: Percentual mÃ­nimo para considerar acerto (padrÃ£o: 3.0%)

### CritÃ©rios de ValidaÃ§Ã£o
- **CALL**: Acerto se preÃ§o subiu > +threshold% no horizonte
- **PUT**: Acerto se preÃ§o caiu > -threshold% no horizonte
- **NEUTRAL**: Acerto se preÃ§o ficou entre Â±threshold%

## ğŸ“Š MÃ©tricas Calculadas

### EstatÃ­sticas Gerais
- Taxa de acerto geral (%)
- AcurÃ¡cia por tipo de sinal (CALL/PUT/NEUTRAL)
- AcurÃ¡cia por nÃ­vel de confianÃ§a (Alta â‰¥70%, MÃ©dia 50-69%, Baixa <50%)

### Performance Qualitativa
- **Excelente**: â‰¥60% de acurÃ¡cia
- **Boa**: 50-59% de acurÃ¡cia
- **Regular**: 40-49% de acurÃ¡cia
- **Precisa Melhorar**: <40% de acurÃ¡cia

## ğŸ“ˆ VisualizaÃ§Ãµes DisponÃ­veis

1. **PreÃ§o com Sinais**: GrÃ¡fico de preÃ§o com marcadores coloridos para cada sinal
2. **Breakdown de AcurÃ¡cia**: Barras comparando acurÃ¡cia por tipo e confianÃ§a
3. **DistribuiÃ§Ã£o de Retornos**: Histogramas dos retornos por tipo de sinal
4. **ConfianÃ§a vs Resultado**: Scatter plot para identificar padrÃµes
5. **Performance Temporal**: AcurÃ¡cia mÃ³vel ao longo do tempo

## ğŸ”§ ConfiguraÃ§Ã£o para ProduÃ§Ã£o

Para usar com dados reais da API OpLab, configure as variÃ¡veis de ambiente:

```bash
export OPLAB_API_BASE_URL="https://api.oplab.com.br"
export OPLAB_API_KEY="sua_chave_aqui"
# ... outras variÃ¡veis conforme oplab_client.py
```

## ğŸ“‹ Exemplo de SaÃ­da

```
ğŸ“Š RESUMO DO BACKTEST - PETR4
============================================================
ğŸ“… PerÃ­odo: 01/01/2023 a 01/01/2025
â±ï¸ Horizonte de avaliaÃ§Ã£o: 20 dias Ãºteis
ğŸ¯ Threshold de sucesso: Â±3.0%

ğŸ“ˆ ESTATÃSTICAS GERAIS:
â€¢ Total de sinais: 87
â€¢ AcurÃ¡cia geral: 62.1%

ğŸ“Š ACURÃCIA POR SINAL:
â€¢ CALL (29 sinais): 65.5%
â€¢ PUT (31 sinais): 58.1%
â€¢ NEUTRAL (27 sinais): 63.0%

ğŸ¯ ACURÃCIA POR CONFIANÃ‡A:
â€¢ Alta confianÃ§a (â‰¥70%, 32 sinais): 75.0%
â€¢ MÃ©dia confianÃ§a (50-69%, 41 sinais): 56.1%
â€¢ Baixa confianÃ§a (<50%, 14 sinais): 42.9%

ğŸ‰ PERFORMANCE: EXCELENTE (â‰¥60%)
============================================================
```

## ğŸ¯ Insights AutomÃ¡ticos

O sistema gera insights automÃ¡ticos baseados nos resultados:
- Performance geral vs benchmarks
- EficÃ¡cia de sinais de alta confianÃ§a
- Melhor tipo de sinal para o ativo
- SugestÃµes de otimizaÃ§Ã£o

## ğŸ“ ExportaÃ§Ã£o

- **CSV**: Tabela completa de sinais com resultados
- **PNG**: GrÃ¡ficos interativos (via botÃ£o de cÃ¢mera)
- **Texto**: Resumo executivo formatado para relatÃ³rios

## ğŸ” LimitaÃ§Ãµes Atuais

1. **Dados Simulados**: Por padrÃ£o usa dados simulados (mÃ³dulo `data.py`)
2. **API Dependency**: Requer configuraÃ§Ã£o da API OpLab para dados reais
3. **Horizonte Fixo**: Avalia todos os sinais no mesmo horizonte temporal
4. **Sem Custos**: NÃ£o considera custos de transaÃ§Ã£o ou spread

## ğŸš€ PrÃ³ximas Melhorias

- [ ] IntegraÃ§Ã£o com dados reais de mÃºltiplas fontes
- [ ] AnÃ¡lise de custos de transaÃ§Ã£o
- [ ] Backtests multi-ativo simultÃ¢neos
- [ ] OtimizaÃ§Ã£o automÃ¡tica de parÃ¢metros
- [ ] ComparaÃ§Ã£o com benchmarks de mercado
- [ ] AnÃ¡lise de drawdown e Sharpe ratio

---

**Desenvolvido para validar e otimizar o ProfessionalAnalyzer** ğŸ¯
